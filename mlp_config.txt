MLP Configuration (Accuracy: 84.09%)
hidden_layer_sizes = (1024, 512, 256, 128, 64, 32, 16, 8)
activation = relu
solver = adam
alpha = 1e-05
batch_size = 32
learning_rate = adaptive
learning_rate_init = 0.0005
max_iter = 3000
early_stopping = True
validation_fraction = 0.1
n_iter_no_change = 50
random_state = 42
